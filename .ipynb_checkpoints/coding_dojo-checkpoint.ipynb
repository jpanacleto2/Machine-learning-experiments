{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdd3ca8",
   "metadata": {},
   "source": [
    "# Coding Dojo (Word embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como fazer um coding dojo?\n",
    "\n",
    "Papéis:\n",
    "SENSEI: é a pessoa que traz o desafio e ministra a edição do evento;\n",
    "PILOTO: é a pessoa que está programando;\n",
    "CO-PILOTO: é o par do piloto na rodada atual, que tem como principal função auxiliar no entendimento do problema.\n",
    "\n",
    "Preparando o ambiente:\n",
    "Precisamos ter uma forma rápida e fácil de instalar as dependências do dojo nos computadores de todos os envolvidos. Então ter um tutorial bem estruturado é essencial em um dojo.\n",
    "\n",
    "Escrevendo o desafio:\n",
    "Quando iniciamos o desafio, fazemos uma breve introdução do que é o tema, e o que iremos fazer. Logo após isso, é essencial que você explique o passo a passo o que os participantes têm que fazer. O ideal é que você vá transmitindo o seu código e fazendo junto com eles. É no final deixar uns 10 minutos para quaisquer dúvidas.\n",
    "\n",
    "\n",
    "2. Preparando o ambiente:\n",
    "\n",
    "pip install spacy\n",
    "\n",
    "python -m spacy download pt_core_news_sm\n",
    "\n",
    "pip install unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fabeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619ab69",
   "metadata": {},
   "source": [
    "### Função para pré-processamento:\n",
    "Antes de importarmos os dados, é interressante criar uma função de **pre-processamento** para limpar a base de dados. Lembrando que essa parte é essencial quando queremos trabalhar com análise de textos, principalmente quando queremos aplicar um modelo de predição ou outros métodos estatísticos. São muitos os métodos de pré-processamento, mas aqui vamos realizar apenas alguns:\n",
    "- Transformam todos os caracteres em minusculas;\n",
    "- Remove as acentuações\n",
    "- Remove as pontuações\n",
    "- Remove números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9749448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(texto):\n",
    "        texto = unidecode(texto)\n",
    "        texto = texto.lower()\n",
    "        texto = texto.translate(str.maketrans('','', string.punctuation))\n",
    "        texto = re.sub(r'[0-9]+', '', texto)\n",
    "        return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos importar os dados, vamos deixar a vontade para que você coloque o texto que quiser nos dois campos abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf015d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_01 = \"Coloque algum texto aqui\"\n",
    "texto_02 = \"Coloque algum texto aqui\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após ter colocado os dois textos, vamos tratar eles. Tirando as palavras que não agregam nenhum valor semântico no texto. Elas são chamadas de \"**STOP WORDS**\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb0491",
   "metadata": {},
   "source": [
    "### Remoção de Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60948c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner(texto_01)\n",
    "cleaner(texto_02)\n",
    "\n",
    "words = nlp.Defaults.stop_words\n",
    "\n",
    "def stopWords(texto_01):\n",
    "    texto_01 = [word for word in texto_01.split() if word not in list(words)]\n",
    "    return ' '.join(texto_01)\n",
    "\n",
    "def stopWords(texto_02):\n",
    "    texto_02 = [word for word in texto_02.split() if word not in list(words)]\n",
    "    return ' '.join(texto_02)\n",
    "\n",
    "print(texto_01)\n",
    "print(texto_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a88c80",
   "metadata": {},
   "source": [
    "### Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precisamos transformar o texto em uma informação numérica, mais especificamente um vetor. Existem, várias formas de se fazer isso, aqui utilizatrmos o TF-IDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora chegamos na parte que queriamos, fazer a assimilaridade entre dois textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como calcular a similaridade entre dois textos usando word embedding?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma função para dizer essa similaridade, no Spacy já temos uma ferramenta que faz isso. Então o processo já fica bastante fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_similaridade(texto1, texto2):\n",
    "    doc1 = nlp(texto1)\n",
    "    doc2 = nlp(texto2)\n",
    "\n",
    "    similaridade = doc1.similarity(doc2)\n",
    "\n",
    "    return similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = calcular_similaridade(texto_01, texto_02)\n",
    "print(f\"A similaridade entre os textos é: {resultado}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
